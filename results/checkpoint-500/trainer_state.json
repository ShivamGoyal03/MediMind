{
  "best_metric": 0.001829268292682927,
  "best_model_checkpoint": "./results\\checkpoint-500",
  "epoch": 2.168021680216802,
  "eval_steps": 100,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04336043360433604,
      "grad_norm": Infinity,
      "learning_rate": 4.5e-07,
      "loss": 9.7643,
      "step": 10
    },
    {
      "epoch": 0.08672086720867209,
      "grad_norm": 8.453700065612793,
      "learning_rate": 9.5e-07,
      "loss": 9.7392,
      "step": 20
    },
    {
      "epoch": 0.13008130081300814,
      "grad_norm": 9.744769096374512,
      "learning_rate": 1.45e-06,
      "loss": 9.753,
      "step": 30
    },
    {
      "epoch": 0.17344173441734417,
      "grad_norm": 11.375333786010742,
      "learning_rate": 1.95e-06,
      "loss": 9.7799,
      "step": 40
    },
    {
      "epoch": 0.21680216802168023,
      "grad_norm": 8.270465850830078,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 9.7554,
      "step": 50
    },
    {
      "epoch": 0.2601626016260163,
      "grad_norm": 10.500877380371094,
      "learning_rate": 2.9e-06,
      "loss": 9.7522,
      "step": 60
    },
    {
      "epoch": 0.3035230352303523,
      "grad_norm": 8.821913719177246,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 9.7332,
      "step": 70
    },
    {
      "epoch": 0.34688346883468835,
      "grad_norm": 8.254136085510254,
      "learning_rate": 3.9e-06,
      "loss": 9.7553,
      "step": 80
    },
    {
      "epoch": 0.3902439024390244,
      "grad_norm": 8.818243026733398,
      "learning_rate": 4.4e-06,
      "loss": 9.7594,
      "step": 90
    },
    {
      "epoch": 0.43360433604336046,
      "grad_norm": 10.002685546875,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 9.7904,
      "step": 100
    },
    {
      "epoch": 0.43360433604336046,
      "eval_accuracy": 0.0,
      "eval_loss": 9.76392936706543,
      "eval_runtime": 231.6022,
      "eval_samples_per_second": 7.081,
      "eval_steps_per_second": 1.77,
      "step": 100
    },
    {
      "epoch": 0.47696476964769646,
      "grad_norm": 8.325244903564453,
      "learning_rate": 5.4e-06,
      "loss": 9.7755,
      "step": 110
    },
    {
      "epoch": 0.5203252032520326,
      "grad_norm": 7.5735602378845215,
      "learning_rate": 5.9e-06,
      "loss": 9.7412,
      "step": 120
    },
    {
      "epoch": 0.5636856368563685,
      "grad_norm": 8.107720375061035,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 9.7879,
      "step": 130
    },
    {
      "epoch": 0.6070460704607046,
      "grad_norm": 6.291647911071777,
      "learning_rate": 6.900000000000001e-06,
      "loss": 9.7669,
      "step": 140
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 6.489624977111816,
      "learning_rate": 7.4e-06,
      "loss": 9.7016,
      "step": 150
    },
    {
      "epoch": 0.6937669376693767,
      "grad_norm": Infinity,
      "learning_rate": 7.8e-06,
      "loss": 9.6575,
      "step": 160
    },
    {
      "epoch": 0.7371273712737128,
      "grad_norm": 5.641952991485596,
      "learning_rate": 8.3e-06,
      "loss": 9.702,
      "step": 170
    },
    {
      "epoch": 0.7804878048780488,
      "grad_norm": 7.824916362762451,
      "learning_rate": 8.8e-06,
      "loss": 9.6861,
      "step": 180
    },
    {
      "epoch": 0.8238482384823849,
      "grad_norm": 10.29664421081543,
      "learning_rate": 9.3e-06,
      "loss": 9.7025,
      "step": 190
    },
    {
      "epoch": 0.8672086720867209,
      "grad_norm": 6.419590473175049,
      "learning_rate": 9.800000000000001e-06,
      "loss": 9.6933,
      "step": 200
    },
    {
      "epoch": 0.8672086720867209,
      "eval_accuracy": 0.0,
      "eval_loss": 9.705349922180176,
      "eval_runtime": 231.2537,
      "eval_samples_per_second": 7.092,
      "eval_steps_per_second": 1.773,
      "step": 200
    },
    {
      "epoch": 0.9105691056910569,
      "grad_norm": 10.284307479858398,
      "learning_rate": 1.03e-05,
      "loss": 9.6894,
      "step": 210
    },
    {
      "epoch": 0.9539295392953929,
      "grad_norm": 5.2216997146606445,
      "learning_rate": 1.075e-05,
      "loss": 9.7338,
      "step": 220
    },
    {
      "epoch": 0.997289972899729,
      "grad_norm": 6.723376750946045,
      "learning_rate": 1.125e-05,
      "loss": 9.6863,
      "step": 230
    },
    {
      "epoch": 1.040650406504065,
      "grad_norm": 6.410965442657471,
      "learning_rate": 1.175e-05,
      "loss": 9.6583,
      "step": 240
    },
    {
      "epoch": 1.084010840108401,
      "grad_norm": 5.758727550506592,
      "learning_rate": 1.225e-05,
      "loss": 9.6568,
      "step": 250
    },
    {
      "epoch": 1.127371273712737,
      "grad_norm": 5.456994533538818,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 9.6801,
      "step": 260
    },
    {
      "epoch": 1.170731707317073,
      "grad_norm": 5.843208312988281,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 9.6537,
      "step": 270
    },
    {
      "epoch": 1.2140921409214092,
      "grad_norm": 4.174919605255127,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 9.6403,
      "step": 280
    },
    {
      "epoch": 1.2574525745257452,
      "grad_norm": 4.065707683563232,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 9.6307,
      "step": 290
    },
    {
      "epoch": 1.3008130081300813,
      "grad_norm": 3.6016104221343994,
      "learning_rate": 1.475e-05,
      "loss": 9.6396,
      "step": 300
    },
    {
      "epoch": 1.3008130081300813,
      "eval_accuracy": 0.0,
      "eval_loss": 9.859413146972656,
      "eval_runtime": 227.0025,
      "eval_samples_per_second": 7.225,
      "eval_steps_per_second": 1.806,
      "step": 300
    },
    {
      "epoch": 1.3441734417344173,
      "grad_norm": 4.95908784866333,
      "learning_rate": 1.525e-05,
      "loss": 9.6704,
      "step": 310
    },
    {
      "epoch": 1.3875338753387534,
      "grad_norm": 3.0803775787353516,
      "learning_rate": 1.575e-05,
      "loss": 9.6648,
      "step": 320
    },
    {
      "epoch": 1.4308943089430894,
      "grad_norm": 3.479515552520752,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 9.6318,
      "step": 330
    },
    {
      "epoch": 1.4742547425474255,
      "grad_norm": 3.2046163082122803,
      "learning_rate": 1.675e-05,
      "loss": 9.6451,
      "step": 340
    },
    {
      "epoch": 1.5176151761517616,
      "grad_norm": 3.3723978996276855,
      "learning_rate": 1.725e-05,
      "loss": 9.6461,
      "step": 350
    },
    {
      "epoch": 1.5609756097560976,
      "grad_norm": 3.603956937789917,
      "learning_rate": 1.775e-05,
      "loss": 9.6616,
      "step": 360
    },
    {
      "epoch": 1.6043360433604335,
      "grad_norm": 2.8779473304748535,
      "learning_rate": 1.825e-05,
      "loss": 9.6374,
      "step": 370
    },
    {
      "epoch": 1.6476964769647697,
      "grad_norm": 3.266446352005005,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 9.662,
      "step": 380
    },
    {
      "epoch": 1.6910569105691056,
      "grad_norm": 4.097597122192383,
      "learning_rate": 1.925e-05,
      "loss": 9.6209,
      "step": 390
    },
    {
      "epoch": 1.7344173441734418,
      "grad_norm": 2.9465842247009277,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 9.6744,
      "step": 400
    },
    {
      "epoch": 1.7344173441734418,
      "eval_accuracy": 0.0012195121951219512,
      "eval_loss": 9.97491455078125,
      "eval_runtime": 231.4095,
      "eval_samples_per_second": 7.087,
      "eval_steps_per_second": 1.772,
      "step": 400
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 3.3826746940612793,
      "learning_rate": 2.025e-05,
      "loss": 9.6582,
      "step": 410
    },
    {
      "epoch": 1.821138211382114,
      "grad_norm": 3.0755302906036377,
      "learning_rate": 2.075e-05,
      "loss": 9.6487,
      "step": 420
    },
    {
      "epoch": 1.8644986449864498,
      "grad_norm": 3.590938091278076,
      "learning_rate": 2.125e-05,
      "loss": 9.6522,
      "step": 430
    },
    {
      "epoch": 1.907859078590786,
      "grad_norm": 4.745429039001465,
      "learning_rate": 2.175e-05,
      "loss": 9.6435,
      "step": 440
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 2.9966938495635986,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 9.643,
      "step": 450
    },
    {
      "epoch": 1.994579945799458,
      "grad_norm": 3.122136116027832,
      "learning_rate": 2.275e-05,
      "loss": 9.6548,
      "step": 460
    },
    {
      "epoch": 2.037940379403794,
      "grad_norm": 2.455094575881958,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 9.6174,
      "step": 470
    },
    {
      "epoch": 2.08130081300813,
      "grad_norm": 2.8214869499206543,
      "learning_rate": 2.375e-05,
      "loss": 9.5744,
      "step": 480
    },
    {
      "epoch": 2.124661246612466,
      "grad_norm": 2.2107226848602295,
      "learning_rate": 2.425e-05,
      "loss": 9.5881,
      "step": 490
    },
    {
      "epoch": 2.168021680216802,
      "grad_norm": 2.4148716926574707,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 9.5936,
      "step": 500
    },
    {
      "epoch": 2.168021680216802,
      "eval_accuracy": 0.001829268292682927,
      "eval_loss": 10.093950271606445,
      "eval_runtime": 230.0216,
      "eval_samples_per_second": 7.13,
      "eval_steps_per_second": 1.782,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7832576385024000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
