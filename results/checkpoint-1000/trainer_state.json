{
  "best_metric": 0.003048780487804878,
  "best_model_checkpoint": "./results\\checkpoint-1000",
  "epoch": 4.336043360433604,
  "eval_steps": 100,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04336043360433604,
      "grad_norm": Infinity,
      "learning_rate": 4.5e-07,
      "loss": 9.7643,
      "step": 10
    },
    {
      "epoch": 0.08672086720867209,
      "grad_norm": 8.453700065612793,
      "learning_rate": 9.5e-07,
      "loss": 9.7392,
      "step": 20
    },
    {
      "epoch": 0.13008130081300814,
      "grad_norm": 9.744769096374512,
      "learning_rate": 1.45e-06,
      "loss": 9.753,
      "step": 30
    },
    {
      "epoch": 0.17344173441734417,
      "grad_norm": 11.375333786010742,
      "learning_rate": 1.95e-06,
      "loss": 9.7799,
      "step": 40
    },
    {
      "epoch": 0.21680216802168023,
      "grad_norm": 8.270465850830078,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 9.7554,
      "step": 50
    },
    {
      "epoch": 0.2601626016260163,
      "grad_norm": 10.500877380371094,
      "learning_rate": 2.9e-06,
      "loss": 9.7522,
      "step": 60
    },
    {
      "epoch": 0.3035230352303523,
      "grad_norm": 8.821913719177246,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 9.7332,
      "step": 70
    },
    {
      "epoch": 0.34688346883468835,
      "grad_norm": 8.254136085510254,
      "learning_rate": 3.9e-06,
      "loss": 9.7553,
      "step": 80
    },
    {
      "epoch": 0.3902439024390244,
      "grad_norm": 8.818243026733398,
      "learning_rate": 4.4e-06,
      "loss": 9.7594,
      "step": 90
    },
    {
      "epoch": 0.43360433604336046,
      "grad_norm": 10.002685546875,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 9.7904,
      "step": 100
    },
    {
      "epoch": 0.43360433604336046,
      "eval_accuracy": 0.0,
      "eval_loss": 9.76392936706543,
      "eval_runtime": 231.6022,
      "eval_samples_per_second": 7.081,
      "eval_steps_per_second": 1.77,
      "step": 100
    },
    {
      "epoch": 0.47696476964769646,
      "grad_norm": 8.325244903564453,
      "learning_rate": 5.4e-06,
      "loss": 9.7755,
      "step": 110
    },
    {
      "epoch": 0.5203252032520326,
      "grad_norm": 7.5735602378845215,
      "learning_rate": 5.9e-06,
      "loss": 9.7412,
      "step": 120
    },
    {
      "epoch": 0.5636856368563685,
      "grad_norm": 8.107720375061035,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 9.7879,
      "step": 130
    },
    {
      "epoch": 0.6070460704607046,
      "grad_norm": 6.291647911071777,
      "learning_rate": 6.900000000000001e-06,
      "loss": 9.7669,
      "step": 140
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 6.489624977111816,
      "learning_rate": 7.4e-06,
      "loss": 9.7016,
      "step": 150
    },
    {
      "epoch": 0.6937669376693767,
      "grad_norm": Infinity,
      "learning_rate": 7.8e-06,
      "loss": 9.6575,
      "step": 160
    },
    {
      "epoch": 0.7371273712737128,
      "grad_norm": 5.641952991485596,
      "learning_rate": 8.3e-06,
      "loss": 9.702,
      "step": 170
    },
    {
      "epoch": 0.7804878048780488,
      "grad_norm": 7.824916362762451,
      "learning_rate": 8.8e-06,
      "loss": 9.6861,
      "step": 180
    },
    {
      "epoch": 0.8238482384823849,
      "grad_norm": 10.29664421081543,
      "learning_rate": 9.3e-06,
      "loss": 9.7025,
      "step": 190
    },
    {
      "epoch": 0.8672086720867209,
      "grad_norm": 6.419590473175049,
      "learning_rate": 9.800000000000001e-06,
      "loss": 9.6933,
      "step": 200
    },
    {
      "epoch": 0.8672086720867209,
      "eval_accuracy": 0.0,
      "eval_loss": 9.705349922180176,
      "eval_runtime": 231.2537,
      "eval_samples_per_second": 7.092,
      "eval_steps_per_second": 1.773,
      "step": 200
    },
    {
      "epoch": 0.9105691056910569,
      "grad_norm": 10.284307479858398,
      "learning_rate": 1.03e-05,
      "loss": 9.6894,
      "step": 210
    },
    {
      "epoch": 0.9539295392953929,
      "grad_norm": 5.2216997146606445,
      "learning_rate": 1.075e-05,
      "loss": 9.7338,
      "step": 220
    },
    {
      "epoch": 0.997289972899729,
      "grad_norm": 6.723376750946045,
      "learning_rate": 1.125e-05,
      "loss": 9.6863,
      "step": 230
    },
    {
      "epoch": 1.040650406504065,
      "grad_norm": 6.410965442657471,
      "learning_rate": 1.175e-05,
      "loss": 9.6583,
      "step": 240
    },
    {
      "epoch": 1.084010840108401,
      "grad_norm": 5.758727550506592,
      "learning_rate": 1.225e-05,
      "loss": 9.6568,
      "step": 250
    },
    {
      "epoch": 1.127371273712737,
      "grad_norm": 5.456994533538818,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 9.6801,
      "step": 260
    },
    {
      "epoch": 1.170731707317073,
      "grad_norm": 5.843208312988281,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 9.6537,
      "step": 270
    },
    {
      "epoch": 1.2140921409214092,
      "grad_norm": 4.174919605255127,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 9.6403,
      "step": 280
    },
    {
      "epoch": 1.2574525745257452,
      "grad_norm": 4.065707683563232,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 9.6307,
      "step": 290
    },
    {
      "epoch": 1.3008130081300813,
      "grad_norm": 3.6016104221343994,
      "learning_rate": 1.475e-05,
      "loss": 9.6396,
      "step": 300
    },
    {
      "epoch": 1.3008130081300813,
      "eval_accuracy": 0.0,
      "eval_loss": 9.859413146972656,
      "eval_runtime": 227.0025,
      "eval_samples_per_second": 7.225,
      "eval_steps_per_second": 1.806,
      "step": 300
    },
    {
      "epoch": 1.3441734417344173,
      "grad_norm": 4.95908784866333,
      "learning_rate": 1.525e-05,
      "loss": 9.6704,
      "step": 310
    },
    {
      "epoch": 1.3875338753387534,
      "grad_norm": 3.0803775787353516,
      "learning_rate": 1.575e-05,
      "loss": 9.6648,
      "step": 320
    },
    {
      "epoch": 1.4308943089430894,
      "grad_norm": 3.479515552520752,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 9.6318,
      "step": 330
    },
    {
      "epoch": 1.4742547425474255,
      "grad_norm": 3.2046163082122803,
      "learning_rate": 1.675e-05,
      "loss": 9.6451,
      "step": 340
    },
    {
      "epoch": 1.5176151761517616,
      "grad_norm": 3.3723978996276855,
      "learning_rate": 1.725e-05,
      "loss": 9.6461,
      "step": 350
    },
    {
      "epoch": 1.5609756097560976,
      "grad_norm": 3.603956937789917,
      "learning_rate": 1.775e-05,
      "loss": 9.6616,
      "step": 360
    },
    {
      "epoch": 1.6043360433604335,
      "grad_norm": 2.8779473304748535,
      "learning_rate": 1.825e-05,
      "loss": 9.6374,
      "step": 370
    },
    {
      "epoch": 1.6476964769647697,
      "grad_norm": 3.266446352005005,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 9.662,
      "step": 380
    },
    {
      "epoch": 1.6910569105691056,
      "grad_norm": 4.097597122192383,
      "learning_rate": 1.925e-05,
      "loss": 9.6209,
      "step": 390
    },
    {
      "epoch": 1.7344173441734418,
      "grad_norm": 2.9465842247009277,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 9.6744,
      "step": 400
    },
    {
      "epoch": 1.7344173441734418,
      "eval_accuracy": 0.0012195121951219512,
      "eval_loss": 9.97491455078125,
      "eval_runtime": 231.4095,
      "eval_samples_per_second": 7.087,
      "eval_steps_per_second": 1.772,
      "step": 400
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 3.3826746940612793,
      "learning_rate": 2.025e-05,
      "loss": 9.6582,
      "step": 410
    },
    {
      "epoch": 1.821138211382114,
      "grad_norm": 3.0755302906036377,
      "learning_rate": 2.075e-05,
      "loss": 9.6487,
      "step": 420
    },
    {
      "epoch": 1.8644986449864498,
      "grad_norm": 3.590938091278076,
      "learning_rate": 2.125e-05,
      "loss": 9.6522,
      "step": 430
    },
    {
      "epoch": 1.907859078590786,
      "grad_norm": 4.745429039001465,
      "learning_rate": 2.175e-05,
      "loss": 9.6435,
      "step": 440
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 2.9966938495635986,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 9.643,
      "step": 450
    },
    {
      "epoch": 1.994579945799458,
      "grad_norm": 3.122136116027832,
      "learning_rate": 2.275e-05,
      "loss": 9.6548,
      "step": 460
    },
    {
      "epoch": 2.037940379403794,
      "grad_norm": 2.455094575881958,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 9.6174,
      "step": 470
    },
    {
      "epoch": 2.08130081300813,
      "grad_norm": 2.8214869499206543,
      "learning_rate": 2.375e-05,
      "loss": 9.5744,
      "step": 480
    },
    {
      "epoch": 2.124661246612466,
      "grad_norm": 2.2107226848602295,
      "learning_rate": 2.425e-05,
      "loss": 9.5881,
      "step": 490
    },
    {
      "epoch": 2.168021680216802,
      "grad_norm": 2.4148716926574707,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 9.5936,
      "step": 500
    },
    {
      "epoch": 2.168021680216802,
      "eval_accuracy": 0.001829268292682927,
      "eval_loss": 10.093950271606445,
      "eval_runtime": 230.0216,
      "eval_samples_per_second": 7.13,
      "eval_steps_per_second": 1.782,
      "step": 500
    },
    {
      "epoch": 2.2113821138211383,
      "grad_norm": 2.4732463359832764,
      "learning_rate": 2.525e-05,
      "loss": 9.5648,
      "step": 510
    },
    {
      "epoch": 2.254742547425474,
      "grad_norm": 2.527837038040161,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 9.5855,
      "step": 520
    },
    {
      "epoch": 2.2981029810298104,
      "grad_norm": 3.0360920429229736,
      "learning_rate": 2.625e-05,
      "loss": 9.5474,
      "step": 530
    },
    {
      "epoch": 2.341463414634146,
      "grad_norm": 2.7373034954071045,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 9.5878,
      "step": 540
    },
    {
      "epoch": 2.3848238482384825,
      "grad_norm": 2.660691022872925,
      "learning_rate": 2.725e-05,
      "loss": 9.6056,
      "step": 550
    },
    {
      "epoch": 2.4281842818428183,
      "grad_norm": 2.4933998584747314,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 9.5958,
      "step": 560
    },
    {
      "epoch": 2.4715447154471546,
      "grad_norm": 2.5547733306884766,
      "learning_rate": 2.825e-05,
      "loss": 9.5809,
      "step": 570
    },
    {
      "epoch": 2.5149051490514904,
      "grad_norm": 2.8680977821350098,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 9.5963,
      "step": 580
    },
    {
      "epoch": 2.5582655826558267,
      "grad_norm": 2.6906239986419678,
      "learning_rate": 2.925e-05,
      "loss": 9.6152,
      "step": 590
    },
    {
      "epoch": 2.6016260162601625,
      "grad_norm": 2.9956510066986084,
      "learning_rate": 2.975e-05,
      "loss": 9.6427,
      "step": 600
    },
    {
      "epoch": 2.6016260162601625,
      "eval_accuracy": 0.0012195121951219512,
      "eval_loss": 10.175233840942383,
      "eval_runtime": 230.2791,
      "eval_samples_per_second": 7.122,
      "eval_steps_per_second": 1.78,
      "step": 600
    },
    {
      "epoch": 2.644986449864499,
      "grad_norm": 2.3856747150421143,
      "learning_rate": 3.025e-05,
      "loss": 9.6005,
      "step": 610
    },
    {
      "epoch": 2.6883468834688347,
      "grad_norm": 2.5680501461029053,
      "learning_rate": 3.075e-05,
      "loss": 9.6075,
      "step": 620
    },
    {
      "epoch": 2.7317073170731705,
      "grad_norm": 2.422698974609375,
      "learning_rate": 3.125e-05,
      "loss": 9.6048,
      "step": 630
    },
    {
      "epoch": 2.7750677506775068,
      "grad_norm": 2.499603509902954,
      "learning_rate": 3.175e-05,
      "loss": 9.6208,
      "step": 640
    },
    {
      "epoch": 2.818428184281843,
      "grad_norm": 2.502742290496826,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 9.5947,
      "step": 650
    },
    {
      "epoch": 2.861788617886179,
      "grad_norm": 2.6502513885498047,
      "learning_rate": 3.275e-05,
      "loss": 9.6197,
      "step": 660
    },
    {
      "epoch": 2.9051490514905147,
      "grad_norm": 2.9868552684783936,
      "learning_rate": 3.325e-05,
      "loss": 9.5869,
      "step": 670
    },
    {
      "epoch": 2.948509485094851,
      "grad_norm": 2.483806848526001,
      "learning_rate": 3.375000000000001e-05,
      "loss": 9.5892,
      "step": 680
    },
    {
      "epoch": 2.991869918699187,
      "grad_norm": 2.5160913467407227,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 9.5873,
      "step": 690
    },
    {
      "epoch": 3.035230352303523,
      "grad_norm": 3.497659683227539,
      "learning_rate": 3.475e-05,
      "loss": 9.4622,
      "step": 700
    },
    {
      "epoch": 3.035230352303523,
      "eval_accuracy": 0.0024390243902439024,
      "eval_loss": 10.436132431030273,
      "eval_runtime": 231.4329,
      "eval_samples_per_second": 7.086,
      "eval_steps_per_second": 1.772,
      "step": 700
    },
    {
      "epoch": 3.078590785907859,
      "grad_norm": 2.8888819217681885,
      "learning_rate": 3.525e-05,
      "loss": 9.4451,
      "step": 710
    },
    {
      "epoch": 3.1219512195121952,
      "grad_norm": 3.4610726833343506,
      "learning_rate": 3.575e-05,
      "loss": 9.4082,
      "step": 720
    },
    {
      "epoch": 3.165311653116531,
      "grad_norm": 3.210242509841919,
      "learning_rate": 3.625e-05,
      "loss": 9.4349,
      "step": 730
    },
    {
      "epoch": 3.2086720867208673,
      "grad_norm": 3.515918731689453,
      "learning_rate": 3.675e-05,
      "loss": 9.3894,
      "step": 740
    },
    {
      "epoch": 3.252032520325203,
      "grad_norm": 3.6226019859313965,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 9.4279,
      "step": 750
    },
    {
      "epoch": 3.2953929539295395,
      "grad_norm": 3.5050997734069824,
      "learning_rate": 3.775e-05,
      "loss": 9.4202,
      "step": 760
    },
    {
      "epoch": 3.3387533875338753,
      "grad_norm": 3.2615957260131836,
      "learning_rate": 3.825e-05,
      "loss": 9.4369,
      "step": 770
    },
    {
      "epoch": 3.3821138211382116,
      "grad_norm": 3.351378917694092,
      "learning_rate": 3.875e-05,
      "loss": 9.4182,
      "step": 780
    },
    {
      "epoch": 3.4254742547425474,
      "grad_norm": 3.1986234188079834,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 9.4541,
      "step": 790
    },
    {
      "epoch": 3.4688346883468837,
      "grad_norm": 3.1914992332458496,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 9.4496,
      "step": 800
    },
    {
      "epoch": 3.4688346883468837,
      "eval_accuracy": 0.00426829268292683,
      "eval_loss": 10.582066535949707,
      "eval_runtime": 229.4548,
      "eval_samples_per_second": 7.147,
      "eval_steps_per_second": 1.787,
      "step": 800
    },
    {
      "epoch": 3.5121951219512195,
      "grad_norm": 3.5021612644195557,
      "learning_rate": 4.025e-05,
      "loss": 9.4037,
      "step": 810
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 3.39107608795166,
      "learning_rate": 4.075e-05,
      "loss": 9.4119,
      "step": 820
    },
    {
      "epoch": 3.5989159891598916,
      "grad_norm": 3.365405321121216,
      "learning_rate": 4.125e-05,
      "loss": 9.4058,
      "step": 830
    },
    {
      "epoch": 3.642276422764228,
      "grad_norm": 3.3252689838409424,
      "learning_rate": 4.175e-05,
      "loss": 9.4683,
      "step": 840
    },
    {
      "epoch": 3.6856368563685638,
      "grad_norm": 3.603492021560669,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 9.3968,
      "step": 850
    },
    {
      "epoch": 3.7289972899728996,
      "grad_norm": 3.4287331104278564,
      "learning_rate": 4.275e-05,
      "loss": 9.4052,
      "step": 860
    },
    {
      "epoch": 3.772357723577236,
      "grad_norm": 3.5004770755767822,
      "learning_rate": 4.325e-05,
      "loss": 9.4059,
      "step": 870
    },
    {
      "epoch": 3.8157181571815717,
      "grad_norm": 3.510524272918701,
      "learning_rate": 4.375e-05,
      "loss": 9.4238,
      "step": 880
    },
    {
      "epoch": 3.859078590785908,
      "grad_norm": 3.486476421356201,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 9.4603,
      "step": 890
    },
    {
      "epoch": 3.902439024390244,
      "grad_norm": 3.4445159435272217,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 9.4373,
      "step": 900
    },
    {
      "epoch": 3.902439024390244,
      "eval_accuracy": 0.003048780487804878,
      "eval_loss": 10.729153633117676,
      "eval_runtime": 231.0308,
      "eval_samples_per_second": 7.099,
      "eval_steps_per_second": 1.775,
      "step": 900
    },
    {
      "epoch": 3.94579945799458,
      "grad_norm": 3.3804571628570557,
      "learning_rate": 4.525e-05,
      "loss": 9.4115,
      "step": 910
    },
    {
      "epoch": 3.989159891598916,
      "grad_norm": 3.329535961151123,
      "learning_rate": 4.575e-05,
      "loss": 9.4224,
      "step": 920
    },
    {
      "epoch": 4.032520325203252,
      "grad_norm": 3.8495264053344727,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 9.1898,
      "step": 930
    },
    {
      "epoch": 4.075880758807588,
      "grad_norm": 4.345518112182617,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 9.031,
      "step": 940
    },
    {
      "epoch": 4.119241192411924,
      "grad_norm": 4.004621505737305,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 9.0058,
      "step": 950
    },
    {
      "epoch": 4.16260162601626,
      "grad_norm": 3.9499216079711914,
      "learning_rate": 4.775e-05,
      "loss": 9.0789,
      "step": 960
    },
    {
      "epoch": 4.205962059620596,
      "grad_norm": 4.125730991363525,
      "learning_rate": 4.825e-05,
      "loss": 8.9906,
      "step": 970
    },
    {
      "epoch": 4.249322493224932,
      "grad_norm": 4.5427937507629395,
      "learning_rate": 4.875e-05,
      "loss": 9.042,
      "step": 980
    },
    {
      "epoch": 4.2926829268292686,
      "grad_norm": 3.936816453933716,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 9.0162,
      "step": 990
    },
    {
      "epoch": 4.336043360433604,
      "grad_norm": 3.9106459617614746,
      "learning_rate": 4.975e-05,
      "loss": 9.069,
      "step": 1000
    },
    {
      "epoch": 4.336043360433604,
      "eval_accuracy": 0.003048780487804878,
      "eval_loss": 10.494622230529785,
      "eval_runtime": 231.5831,
      "eval_samples_per_second": 7.082,
      "eval_steps_per_second": 1.77,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5665152770048e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
