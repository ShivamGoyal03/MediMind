{
  "best_metric": 0.006707317073170732,
  "best_model_checkpoint": "./results\\checkpoint-1500",
  "epoch": 6.504065040650406,
  "eval_steps": 100,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04336043360433604,
      "grad_norm": Infinity,
      "learning_rate": 4.5e-07,
      "loss": 9.7643,
      "step": 10
    },
    {
      "epoch": 0.08672086720867209,
      "grad_norm": 8.453700065612793,
      "learning_rate": 9.5e-07,
      "loss": 9.7392,
      "step": 20
    },
    {
      "epoch": 0.13008130081300814,
      "grad_norm": 9.744769096374512,
      "learning_rate": 1.45e-06,
      "loss": 9.753,
      "step": 30
    },
    {
      "epoch": 0.17344173441734417,
      "grad_norm": 11.375333786010742,
      "learning_rate": 1.95e-06,
      "loss": 9.7799,
      "step": 40
    },
    {
      "epoch": 0.21680216802168023,
      "grad_norm": 8.270465850830078,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 9.7554,
      "step": 50
    },
    {
      "epoch": 0.2601626016260163,
      "grad_norm": 10.500877380371094,
      "learning_rate": 2.9e-06,
      "loss": 9.7522,
      "step": 60
    },
    {
      "epoch": 0.3035230352303523,
      "grad_norm": 8.821913719177246,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 9.7332,
      "step": 70
    },
    {
      "epoch": 0.34688346883468835,
      "grad_norm": 8.254136085510254,
      "learning_rate": 3.9e-06,
      "loss": 9.7553,
      "step": 80
    },
    {
      "epoch": 0.3902439024390244,
      "grad_norm": 8.818243026733398,
      "learning_rate": 4.4e-06,
      "loss": 9.7594,
      "step": 90
    },
    {
      "epoch": 0.43360433604336046,
      "grad_norm": 10.002685546875,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 9.7904,
      "step": 100
    },
    {
      "epoch": 0.43360433604336046,
      "eval_accuracy": 0.0,
      "eval_loss": 9.76392936706543,
      "eval_runtime": 231.6022,
      "eval_samples_per_second": 7.081,
      "eval_steps_per_second": 1.77,
      "step": 100
    },
    {
      "epoch": 0.47696476964769646,
      "grad_norm": 8.325244903564453,
      "learning_rate": 5.4e-06,
      "loss": 9.7755,
      "step": 110
    },
    {
      "epoch": 0.5203252032520326,
      "grad_norm": 7.5735602378845215,
      "learning_rate": 5.9e-06,
      "loss": 9.7412,
      "step": 120
    },
    {
      "epoch": 0.5636856368563685,
      "grad_norm": 8.107720375061035,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 9.7879,
      "step": 130
    },
    {
      "epoch": 0.6070460704607046,
      "grad_norm": 6.291647911071777,
      "learning_rate": 6.900000000000001e-06,
      "loss": 9.7669,
      "step": 140
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 6.489624977111816,
      "learning_rate": 7.4e-06,
      "loss": 9.7016,
      "step": 150
    },
    {
      "epoch": 0.6937669376693767,
      "grad_norm": Infinity,
      "learning_rate": 7.8e-06,
      "loss": 9.6575,
      "step": 160
    },
    {
      "epoch": 0.7371273712737128,
      "grad_norm": 5.641952991485596,
      "learning_rate": 8.3e-06,
      "loss": 9.702,
      "step": 170
    },
    {
      "epoch": 0.7804878048780488,
      "grad_norm": 7.824916362762451,
      "learning_rate": 8.8e-06,
      "loss": 9.6861,
      "step": 180
    },
    {
      "epoch": 0.8238482384823849,
      "grad_norm": 10.29664421081543,
      "learning_rate": 9.3e-06,
      "loss": 9.7025,
      "step": 190
    },
    {
      "epoch": 0.8672086720867209,
      "grad_norm": 6.419590473175049,
      "learning_rate": 9.800000000000001e-06,
      "loss": 9.6933,
      "step": 200
    },
    {
      "epoch": 0.8672086720867209,
      "eval_accuracy": 0.0,
      "eval_loss": 9.705349922180176,
      "eval_runtime": 231.2537,
      "eval_samples_per_second": 7.092,
      "eval_steps_per_second": 1.773,
      "step": 200
    },
    {
      "epoch": 0.9105691056910569,
      "grad_norm": 10.284307479858398,
      "learning_rate": 1.03e-05,
      "loss": 9.6894,
      "step": 210
    },
    {
      "epoch": 0.9539295392953929,
      "grad_norm": 5.2216997146606445,
      "learning_rate": 1.075e-05,
      "loss": 9.7338,
      "step": 220
    },
    {
      "epoch": 0.997289972899729,
      "grad_norm": 6.723376750946045,
      "learning_rate": 1.125e-05,
      "loss": 9.6863,
      "step": 230
    },
    {
      "epoch": 1.040650406504065,
      "grad_norm": 6.410965442657471,
      "learning_rate": 1.175e-05,
      "loss": 9.6583,
      "step": 240
    },
    {
      "epoch": 1.084010840108401,
      "grad_norm": 5.758727550506592,
      "learning_rate": 1.225e-05,
      "loss": 9.6568,
      "step": 250
    },
    {
      "epoch": 1.127371273712737,
      "grad_norm": 5.456994533538818,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 9.6801,
      "step": 260
    },
    {
      "epoch": 1.170731707317073,
      "grad_norm": 5.843208312988281,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 9.6537,
      "step": 270
    },
    {
      "epoch": 1.2140921409214092,
      "grad_norm": 4.174919605255127,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 9.6403,
      "step": 280
    },
    {
      "epoch": 1.2574525745257452,
      "grad_norm": 4.065707683563232,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 9.6307,
      "step": 290
    },
    {
      "epoch": 1.3008130081300813,
      "grad_norm": 3.6016104221343994,
      "learning_rate": 1.475e-05,
      "loss": 9.6396,
      "step": 300
    },
    {
      "epoch": 1.3008130081300813,
      "eval_accuracy": 0.0,
      "eval_loss": 9.859413146972656,
      "eval_runtime": 227.0025,
      "eval_samples_per_second": 7.225,
      "eval_steps_per_second": 1.806,
      "step": 300
    },
    {
      "epoch": 1.3441734417344173,
      "grad_norm": 4.95908784866333,
      "learning_rate": 1.525e-05,
      "loss": 9.6704,
      "step": 310
    },
    {
      "epoch": 1.3875338753387534,
      "grad_norm": 3.0803775787353516,
      "learning_rate": 1.575e-05,
      "loss": 9.6648,
      "step": 320
    },
    {
      "epoch": 1.4308943089430894,
      "grad_norm": 3.479515552520752,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 9.6318,
      "step": 330
    },
    {
      "epoch": 1.4742547425474255,
      "grad_norm": 3.2046163082122803,
      "learning_rate": 1.675e-05,
      "loss": 9.6451,
      "step": 340
    },
    {
      "epoch": 1.5176151761517616,
      "grad_norm": 3.3723978996276855,
      "learning_rate": 1.725e-05,
      "loss": 9.6461,
      "step": 350
    },
    {
      "epoch": 1.5609756097560976,
      "grad_norm": 3.603956937789917,
      "learning_rate": 1.775e-05,
      "loss": 9.6616,
      "step": 360
    },
    {
      "epoch": 1.6043360433604335,
      "grad_norm": 2.8779473304748535,
      "learning_rate": 1.825e-05,
      "loss": 9.6374,
      "step": 370
    },
    {
      "epoch": 1.6476964769647697,
      "grad_norm": 3.266446352005005,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 9.662,
      "step": 380
    },
    {
      "epoch": 1.6910569105691056,
      "grad_norm": 4.097597122192383,
      "learning_rate": 1.925e-05,
      "loss": 9.6209,
      "step": 390
    },
    {
      "epoch": 1.7344173441734418,
      "grad_norm": 2.9465842247009277,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 9.6744,
      "step": 400
    },
    {
      "epoch": 1.7344173441734418,
      "eval_accuracy": 0.0012195121951219512,
      "eval_loss": 9.97491455078125,
      "eval_runtime": 231.4095,
      "eval_samples_per_second": 7.087,
      "eval_steps_per_second": 1.772,
      "step": 400
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 3.3826746940612793,
      "learning_rate": 2.025e-05,
      "loss": 9.6582,
      "step": 410
    },
    {
      "epoch": 1.821138211382114,
      "grad_norm": 3.0755302906036377,
      "learning_rate": 2.075e-05,
      "loss": 9.6487,
      "step": 420
    },
    {
      "epoch": 1.8644986449864498,
      "grad_norm": 3.590938091278076,
      "learning_rate": 2.125e-05,
      "loss": 9.6522,
      "step": 430
    },
    {
      "epoch": 1.907859078590786,
      "grad_norm": 4.745429039001465,
      "learning_rate": 2.175e-05,
      "loss": 9.6435,
      "step": 440
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 2.9966938495635986,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 9.643,
      "step": 450
    },
    {
      "epoch": 1.994579945799458,
      "grad_norm": 3.122136116027832,
      "learning_rate": 2.275e-05,
      "loss": 9.6548,
      "step": 460
    },
    {
      "epoch": 2.037940379403794,
      "grad_norm": 2.455094575881958,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 9.6174,
      "step": 470
    },
    {
      "epoch": 2.08130081300813,
      "grad_norm": 2.8214869499206543,
      "learning_rate": 2.375e-05,
      "loss": 9.5744,
      "step": 480
    },
    {
      "epoch": 2.124661246612466,
      "grad_norm": 2.2107226848602295,
      "learning_rate": 2.425e-05,
      "loss": 9.5881,
      "step": 490
    },
    {
      "epoch": 2.168021680216802,
      "grad_norm": 2.4148716926574707,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 9.5936,
      "step": 500
    },
    {
      "epoch": 2.168021680216802,
      "eval_accuracy": 0.001829268292682927,
      "eval_loss": 10.093950271606445,
      "eval_runtime": 230.0216,
      "eval_samples_per_second": 7.13,
      "eval_steps_per_second": 1.782,
      "step": 500
    },
    {
      "epoch": 2.2113821138211383,
      "grad_norm": 2.4732463359832764,
      "learning_rate": 2.525e-05,
      "loss": 9.5648,
      "step": 510
    },
    {
      "epoch": 2.254742547425474,
      "grad_norm": 2.527837038040161,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 9.5855,
      "step": 520
    },
    {
      "epoch": 2.2981029810298104,
      "grad_norm": 3.0360920429229736,
      "learning_rate": 2.625e-05,
      "loss": 9.5474,
      "step": 530
    },
    {
      "epoch": 2.341463414634146,
      "grad_norm": 2.7373034954071045,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 9.5878,
      "step": 540
    },
    {
      "epoch": 2.3848238482384825,
      "grad_norm": 2.660691022872925,
      "learning_rate": 2.725e-05,
      "loss": 9.6056,
      "step": 550
    },
    {
      "epoch": 2.4281842818428183,
      "grad_norm": 2.4933998584747314,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 9.5958,
      "step": 560
    },
    {
      "epoch": 2.4715447154471546,
      "grad_norm": 2.5547733306884766,
      "learning_rate": 2.825e-05,
      "loss": 9.5809,
      "step": 570
    },
    {
      "epoch": 2.5149051490514904,
      "grad_norm": 2.8680977821350098,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 9.5963,
      "step": 580
    },
    {
      "epoch": 2.5582655826558267,
      "grad_norm": 2.6906239986419678,
      "learning_rate": 2.925e-05,
      "loss": 9.6152,
      "step": 590
    },
    {
      "epoch": 2.6016260162601625,
      "grad_norm": 2.9956510066986084,
      "learning_rate": 2.975e-05,
      "loss": 9.6427,
      "step": 600
    },
    {
      "epoch": 2.6016260162601625,
      "eval_accuracy": 0.0012195121951219512,
      "eval_loss": 10.175233840942383,
      "eval_runtime": 230.2791,
      "eval_samples_per_second": 7.122,
      "eval_steps_per_second": 1.78,
      "step": 600
    },
    {
      "epoch": 2.644986449864499,
      "grad_norm": 2.3856747150421143,
      "learning_rate": 3.025e-05,
      "loss": 9.6005,
      "step": 610
    },
    {
      "epoch": 2.6883468834688347,
      "grad_norm": 2.5680501461029053,
      "learning_rate": 3.075e-05,
      "loss": 9.6075,
      "step": 620
    },
    {
      "epoch": 2.7317073170731705,
      "grad_norm": 2.422698974609375,
      "learning_rate": 3.125e-05,
      "loss": 9.6048,
      "step": 630
    },
    {
      "epoch": 2.7750677506775068,
      "grad_norm": 2.499603509902954,
      "learning_rate": 3.175e-05,
      "loss": 9.6208,
      "step": 640
    },
    {
      "epoch": 2.818428184281843,
      "grad_norm": 2.502742290496826,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 9.5947,
      "step": 650
    },
    {
      "epoch": 2.861788617886179,
      "grad_norm": 2.6502513885498047,
      "learning_rate": 3.275e-05,
      "loss": 9.6197,
      "step": 660
    },
    {
      "epoch": 2.9051490514905147,
      "grad_norm": 2.9868552684783936,
      "learning_rate": 3.325e-05,
      "loss": 9.5869,
      "step": 670
    },
    {
      "epoch": 2.948509485094851,
      "grad_norm": 2.483806848526001,
      "learning_rate": 3.375000000000001e-05,
      "loss": 9.5892,
      "step": 680
    },
    {
      "epoch": 2.991869918699187,
      "grad_norm": 2.5160913467407227,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 9.5873,
      "step": 690
    },
    {
      "epoch": 3.035230352303523,
      "grad_norm": 3.497659683227539,
      "learning_rate": 3.475e-05,
      "loss": 9.4622,
      "step": 700
    },
    {
      "epoch": 3.035230352303523,
      "eval_accuracy": 0.0024390243902439024,
      "eval_loss": 10.436132431030273,
      "eval_runtime": 231.4329,
      "eval_samples_per_second": 7.086,
      "eval_steps_per_second": 1.772,
      "step": 700
    },
    {
      "epoch": 3.078590785907859,
      "grad_norm": 2.8888819217681885,
      "learning_rate": 3.525e-05,
      "loss": 9.4451,
      "step": 710
    },
    {
      "epoch": 3.1219512195121952,
      "grad_norm": 3.4610726833343506,
      "learning_rate": 3.575e-05,
      "loss": 9.4082,
      "step": 720
    },
    {
      "epoch": 3.165311653116531,
      "grad_norm": 3.210242509841919,
      "learning_rate": 3.625e-05,
      "loss": 9.4349,
      "step": 730
    },
    {
      "epoch": 3.2086720867208673,
      "grad_norm": 3.515918731689453,
      "learning_rate": 3.675e-05,
      "loss": 9.3894,
      "step": 740
    },
    {
      "epoch": 3.252032520325203,
      "grad_norm": 3.6226019859313965,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 9.4279,
      "step": 750
    },
    {
      "epoch": 3.2953929539295395,
      "grad_norm": 3.5050997734069824,
      "learning_rate": 3.775e-05,
      "loss": 9.4202,
      "step": 760
    },
    {
      "epoch": 3.3387533875338753,
      "grad_norm": 3.2615957260131836,
      "learning_rate": 3.825e-05,
      "loss": 9.4369,
      "step": 770
    },
    {
      "epoch": 3.3821138211382116,
      "grad_norm": 3.351378917694092,
      "learning_rate": 3.875e-05,
      "loss": 9.4182,
      "step": 780
    },
    {
      "epoch": 3.4254742547425474,
      "grad_norm": 3.1986234188079834,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 9.4541,
      "step": 790
    },
    {
      "epoch": 3.4688346883468837,
      "grad_norm": 3.1914992332458496,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 9.4496,
      "step": 800
    },
    {
      "epoch": 3.4688346883468837,
      "eval_accuracy": 0.00426829268292683,
      "eval_loss": 10.582066535949707,
      "eval_runtime": 229.4548,
      "eval_samples_per_second": 7.147,
      "eval_steps_per_second": 1.787,
      "step": 800
    },
    {
      "epoch": 3.5121951219512195,
      "grad_norm": 3.5021612644195557,
      "learning_rate": 4.025e-05,
      "loss": 9.4037,
      "step": 810
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 3.39107608795166,
      "learning_rate": 4.075e-05,
      "loss": 9.4119,
      "step": 820
    },
    {
      "epoch": 3.5989159891598916,
      "grad_norm": 3.365405321121216,
      "learning_rate": 4.125e-05,
      "loss": 9.4058,
      "step": 830
    },
    {
      "epoch": 3.642276422764228,
      "grad_norm": 3.3252689838409424,
      "learning_rate": 4.175e-05,
      "loss": 9.4683,
      "step": 840
    },
    {
      "epoch": 3.6856368563685638,
      "grad_norm": 3.603492021560669,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 9.3968,
      "step": 850
    },
    {
      "epoch": 3.7289972899728996,
      "grad_norm": 3.4287331104278564,
      "learning_rate": 4.275e-05,
      "loss": 9.4052,
      "step": 860
    },
    {
      "epoch": 3.772357723577236,
      "grad_norm": 3.5004770755767822,
      "learning_rate": 4.325e-05,
      "loss": 9.4059,
      "step": 870
    },
    {
      "epoch": 3.8157181571815717,
      "grad_norm": 3.510524272918701,
      "learning_rate": 4.375e-05,
      "loss": 9.4238,
      "step": 880
    },
    {
      "epoch": 3.859078590785908,
      "grad_norm": 3.486476421356201,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 9.4603,
      "step": 890
    },
    {
      "epoch": 3.902439024390244,
      "grad_norm": 3.4445159435272217,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 9.4373,
      "step": 900
    },
    {
      "epoch": 3.902439024390244,
      "eval_accuracy": 0.003048780487804878,
      "eval_loss": 10.729153633117676,
      "eval_runtime": 231.0308,
      "eval_samples_per_second": 7.099,
      "eval_steps_per_second": 1.775,
      "step": 900
    },
    {
      "epoch": 3.94579945799458,
      "grad_norm": 3.3804571628570557,
      "learning_rate": 4.525e-05,
      "loss": 9.4115,
      "step": 910
    },
    {
      "epoch": 3.989159891598916,
      "grad_norm": 3.329535961151123,
      "learning_rate": 4.575e-05,
      "loss": 9.4224,
      "step": 920
    },
    {
      "epoch": 4.032520325203252,
      "grad_norm": 3.8495264053344727,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 9.1898,
      "step": 930
    },
    {
      "epoch": 4.075880758807588,
      "grad_norm": 4.345518112182617,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 9.031,
      "step": 940
    },
    {
      "epoch": 4.119241192411924,
      "grad_norm": 4.004621505737305,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 9.0058,
      "step": 950
    },
    {
      "epoch": 4.16260162601626,
      "grad_norm": 3.9499216079711914,
      "learning_rate": 4.775e-05,
      "loss": 9.0789,
      "step": 960
    },
    {
      "epoch": 4.205962059620596,
      "grad_norm": 4.125730991363525,
      "learning_rate": 4.825e-05,
      "loss": 8.9906,
      "step": 970
    },
    {
      "epoch": 4.249322493224932,
      "grad_norm": 4.5427937507629395,
      "learning_rate": 4.875e-05,
      "loss": 9.042,
      "step": 980
    },
    {
      "epoch": 4.2926829268292686,
      "grad_norm": 3.936816453933716,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 9.0162,
      "step": 990
    },
    {
      "epoch": 4.336043360433604,
      "grad_norm": 3.9106459617614746,
      "learning_rate": 4.975e-05,
      "loss": 9.069,
      "step": 1000
    },
    {
      "epoch": 4.336043360433604,
      "eval_accuracy": 0.003048780487804878,
      "eval_loss": 10.494622230529785,
      "eval_runtime": 231.5831,
      "eval_samples_per_second": 7.082,
      "eval_steps_per_second": 1.77,
      "step": 1000
    },
    {
      "epoch": 4.37940379403794,
      "grad_norm": 3.9066388607025146,
      "learning_rate": 4.980769230769231e-05,
      "loss": 9.0565,
      "step": 1010
    },
    {
      "epoch": 4.4227642276422765,
      "grad_norm": 3.970468282699585,
      "learning_rate": 4.942307692307693e-05,
      "loss": 9.0817,
      "step": 1020
    },
    {
      "epoch": 4.466124661246613,
      "grad_norm": 4.031592845916748,
      "learning_rate": 4.9038461538461536e-05,
      "loss": 9.0322,
      "step": 1030
    },
    {
      "epoch": 4.509485094850948,
      "grad_norm": 4.402336120605469,
      "learning_rate": 4.865384615384616e-05,
      "loss": 9.0912,
      "step": 1040
    },
    {
      "epoch": 4.5528455284552845,
      "grad_norm": 4.065919876098633,
      "learning_rate": 4.826923076923077e-05,
      "loss": 9.1033,
      "step": 1050
    },
    {
      "epoch": 4.596205962059621,
      "grad_norm": 4.289345741271973,
      "learning_rate": 4.788461538461539e-05,
      "loss": 9.0647,
      "step": 1060
    },
    {
      "epoch": 4.639566395663957,
      "grad_norm": 4.19645357131958,
      "learning_rate": 4.75e-05,
      "loss": 9.088,
      "step": 1070
    },
    {
      "epoch": 4.682926829268292,
      "grad_norm": 4.085386753082275,
      "learning_rate": 4.711538461538462e-05,
      "loss": 9.1131,
      "step": 1080
    },
    {
      "epoch": 4.726287262872629,
      "grad_norm": 4.051997184753418,
      "learning_rate": 4.673076923076923e-05,
      "loss": 9.1097,
      "step": 1090
    },
    {
      "epoch": 4.769647696476965,
      "grad_norm": 4.127105712890625,
      "learning_rate": 4.634615384615385e-05,
      "loss": 9.1527,
      "step": 1100
    },
    {
      "epoch": 4.769647696476965,
      "eval_accuracy": 0.003048780487804878,
      "eval_loss": 10.698600769042969,
      "eval_runtime": 231.5712,
      "eval_samples_per_second": 7.082,
      "eval_steps_per_second": 1.771,
      "step": 1100
    },
    {
      "epoch": 4.8130081300813,
      "grad_norm": 4.369615077972412,
      "learning_rate": 4.596153846153846e-05,
      "loss": 9.0984,
      "step": 1110
    },
    {
      "epoch": 4.856368563685637,
      "grad_norm": 3.961667060852051,
      "learning_rate": 4.557692307692308e-05,
      "loss": 9.1396,
      "step": 1120
    },
    {
      "epoch": 4.899728997289973,
      "grad_norm": 4.21079158782959,
      "learning_rate": 4.519230769230769e-05,
      "loss": 9.1343,
      "step": 1130
    },
    {
      "epoch": 4.943089430894309,
      "grad_norm": 4.139468669891357,
      "learning_rate": 4.4807692307692314e-05,
      "loss": 9.0878,
      "step": 1140
    },
    {
      "epoch": 4.9864498644986455,
      "grad_norm": 3.9276645183563232,
      "learning_rate": 4.442307692307692e-05,
      "loss": 9.1263,
      "step": 1150
    },
    {
      "epoch": 5.029810298102981,
      "grad_norm": 4.203327178955078,
      "learning_rate": 4.403846153846154e-05,
      "loss": 8.7149,
      "step": 1160
    },
    {
      "epoch": 5.073170731707317,
      "grad_norm": 4.301102638244629,
      "learning_rate": 4.365384615384616e-05,
      "loss": 8.5794,
      "step": 1170
    },
    {
      "epoch": 5.116531165311653,
      "grad_norm": 4.358078479766846,
      "learning_rate": 4.326923076923077e-05,
      "loss": 8.5811,
      "step": 1180
    },
    {
      "epoch": 5.159891598915989,
      "grad_norm": 4.31022834777832,
      "learning_rate": 4.288461538461538e-05,
      "loss": 8.5725,
      "step": 1190
    },
    {
      "epoch": 5.203252032520325,
      "grad_norm": 4.638575553894043,
      "learning_rate": 4.25e-05,
      "loss": 8.6189,
      "step": 1200
    },
    {
      "epoch": 5.203252032520325,
      "eval_accuracy": 0.004878048780487805,
      "eval_loss": 10.579862594604492,
      "eval_runtime": 232.3565,
      "eval_samples_per_second": 7.058,
      "eval_steps_per_second": 1.765,
      "step": 1200
    },
    {
      "epoch": 5.246612466124661,
      "grad_norm": 4.3317742347717285,
      "learning_rate": 4.211538461538462e-05,
      "loss": 8.5871,
      "step": 1210
    },
    {
      "epoch": 5.289972899728998,
      "grad_norm": 4.127177715301514,
      "learning_rate": 4.173076923076923e-05,
      "loss": 8.5811,
      "step": 1220
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 4.335701942443848,
      "learning_rate": 4.134615384615385e-05,
      "loss": 8.5721,
      "step": 1230
    },
    {
      "epoch": 5.376693766937669,
      "grad_norm": 4.211338043212891,
      "learning_rate": 4.096153846153846e-05,
      "loss": 8.604,
      "step": 1240
    },
    {
      "epoch": 5.420054200542006,
      "grad_norm": 4.171606540679932,
      "learning_rate": 4.057692307692308e-05,
      "loss": 8.6025,
      "step": 1250
    },
    {
      "epoch": 5.463414634146342,
      "grad_norm": 4.740675926208496,
      "learning_rate": 4.019230769230769e-05,
      "loss": 8.5437,
      "step": 1260
    },
    {
      "epoch": 5.506775067750677,
      "grad_norm": 4.32464075088501,
      "learning_rate": 3.980769230769231e-05,
      "loss": 8.5353,
      "step": 1270
    },
    {
      "epoch": 5.5501355013550135,
      "grad_norm": 4.446717739105225,
      "learning_rate": 3.942307692307692e-05,
      "loss": 8.6212,
      "step": 1280
    },
    {
      "epoch": 5.59349593495935,
      "grad_norm": 4.435184478759766,
      "learning_rate": 3.903846153846154e-05,
      "loss": 8.6637,
      "step": 1290
    },
    {
      "epoch": 5.636856368563686,
      "grad_norm": 4.428670406341553,
      "learning_rate": 3.865384615384616e-05,
      "loss": 8.6705,
      "step": 1300
    },
    {
      "epoch": 5.636856368563686,
      "eval_accuracy": 0.004878048780487805,
      "eval_loss": 10.675354957580566,
      "eval_runtime": 236.3771,
      "eval_samples_per_second": 6.938,
      "eval_steps_per_second": 1.735,
      "step": 1300
    },
    {
      "epoch": 5.6802168021680215,
      "grad_norm": 4.450871467590332,
      "learning_rate": 3.826923076923077e-05,
      "loss": 8.5905,
      "step": 1310
    },
    {
      "epoch": 5.723577235772358,
      "grad_norm": 4.248036861419678,
      "learning_rate": 3.788461538461538e-05,
      "loss": 8.6517,
      "step": 1320
    },
    {
      "epoch": 5.766937669376694,
      "grad_norm": 4.490577697753906,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 8.656,
      "step": 1330
    },
    {
      "epoch": 5.8102981029810294,
      "grad_norm": 4.687926769256592,
      "learning_rate": 3.711538461538462e-05,
      "loss": 8.5864,
      "step": 1340
    },
    {
      "epoch": 5.853658536585366,
      "grad_norm": 4.44835090637207,
      "learning_rate": 3.673076923076923e-05,
      "loss": 8.6401,
      "step": 1350
    },
    {
      "epoch": 5.897018970189702,
      "grad_norm": 4.448334217071533,
      "learning_rate": 3.634615384615385e-05,
      "loss": 8.7285,
      "step": 1360
    },
    {
      "epoch": 5.940379403794038,
      "grad_norm": 4.254135608673096,
      "learning_rate": 3.596153846153846e-05,
      "loss": 8.6737,
      "step": 1370
    },
    {
      "epoch": 5.983739837398374,
      "grad_norm": 4.398617744445801,
      "learning_rate": 3.557692307692308e-05,
      "loss": 8.6616,
      "step": 1380
    },
    {
      "epoch": 6.02710027100271,
      "grad_norm": 4.758970260620117,
      "learning_rate": 3.51923076923077e-05,
      "loss": 8.3674,
      "step": 1390
    },
    {
      "epoch": 6.070460704607046,
      "grad_norm": 4.569128513336182,
      "learning_rate": 3.480769230769231e-05,
      "loss": 8.1824,
      "step": 1400
    },
    {
      "epoch": 6.070460704607046,
      "eval_accuracy": 0.004878048780487805,
      "eval_loss": 10.655547142028809,
      "eval_runtime": 358.0756,
      "eval_samples_per_second": 4.58,
      "eval_steps_per_second": 1.145,
      "step": 1400
    },
    {
      "epoch": 6.1138211382113825,
      "grad_norm": 4.369695663452148,
      "learning_rate": 3.442307692307692e-05,
      "loss": 8.1671,
      "step": 1410
    },
    {
      "epoch": 6.157181571815718,
      "grad_norm": 4.397416114807129,
      "learning_rate": 3.4038461538461544e-05,
      "loss": 8.1855,
      "step": 1420
    },
    {
      "epoch": 6.200542005420054,
      "grad_norm": 4.275537490844727,
      "learning_rate": 3.365384615384616e-05,
      "loss": 8.1696,
      "step": 1430
    },
    {
      "epoch": 6.2439024390243905,
      "grad_norm": 4.299221992492676,
      "learning_rate": 3.326923076923077e-05,
      "loss": 8.1503,
      "step": 1440
    },
    {
      "epoch": 6.287262872628727,
      "grad_norm": 4.587093353271484,
      "learning_rate": 3.288461538461539e-05,
      "loss": 8.1834,
      "step": 1450
    },
    {
      "epoch": 6.330623306233062,
      "grad_norm": 4.405888080596924,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 8.1939,
      "step": 1460
    },
    {
      "epoch": 6.373983739837398,
      "grad_norm": 4.470627784729004,
      "learning_rate": 3.211538461538462e-05,
      "loss": 8.1851,
      "step": 1470
    },
    {
      "epoch": 6.417344173441735,
      "grad_norm": 4.485754013061523,
      "learning_rate": 3.1730769230769234e-05,
      "loss": 8.2084,
      "step": 1480
    },
    {
      "epoch": 6.46070460704607,
      "grad_norm": 4.409832954406738,
      "learning_rate": 3.134615384615385e-05,
      "loss": 8.1879,
      "step": 1490
    },
    {
      "epoch": 6.504065040650406,
      "grad_norm": 4.434277057647705,
      "learning_rate": 3.0961538461538464e-05,
      "loss": 8.1703,
      "step": 1500
    },
    {
      "epoch": 6.504065040650406,
      "eval_accuracy": 0.006707317073170732,
      "eval_loss": 10.670845985412598,
      "eval_runtime": 213.1222,
      "eval_samples_per_second": 7.695,
      "eval_steps_per_second": 1.924,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3497729155072e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
